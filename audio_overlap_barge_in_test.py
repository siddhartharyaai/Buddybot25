#!/usr/bin/env python3
"""
CRITICAL AUDIO OVERLAP, LOOPING, AND BARGE-IN FIXES TESTING
===========================================================

This test specifically validates the critical fixes implemented for:
1. Enhanced Barge-in System with background task cancellation
2. Background TTS Interruption with proper task cancellation  
3. Request Deduplication to prevent duplicate chunk TTS requests
4. Session Management with enhanced session tracking and cleanup
5. Audio overlap prevention and story looping fixes

EXPECTED BEHAVIOR AFTER FIXES:
- Only ONE audio stream playing at any time
- Stories play from beginning to end without loops
- Barge-in immediately stops all audio and background processing
- No duplicate chunk processing
- Clean session transitions
"""

import asyncio
import aiohttp
import json
import base64
import time
import uuid
from datetime import datetime
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AudioOverlapBargeInTester:
    def __init__(self):
        # Use the production URL from frontend/.env
        self.base_url = "https://6ddee563-7037-4e87-80ca-83a8a9a9bcae.preview.emergentagent.com/api"
        self.session = None
        self.test_results = []
        self.active_sessions = []
        
    async def setup(self):
        """Initialize test session"""
        self.session = aiohttp.ClientSession()
        logger.info("üöÄ CRITICAL AUDIO OVERLAP & BARGE-IN TESTING INITIALIZED")
        
    async def cleanup(self):
        """Clean up test session"""
        if self.session:
            await self.session.close()
            
    async def create_test_user(self):
        """Create a test user for audio testing"""
        try:
            user_data = {
                "name": f"AudioTest_{int(time.time())}",
                "age": 8,
                "location": "Test City",
                "timezone": "UTC",
                "language": "english",
                "voice_personality": "friendly_companion",
                "interests": ["stories", "adventures"],
                "learning_goals": ["creativity"],
                "gender": "prefer_not_to_say",
                "avatar": "bunny",
                "speech_speed": "normal",
                "energy_level": "balanced"
            }
            
            async with self.session.post(f"{self.base_url}/users/profile", json=user_data) as response:
                if response.status == 201:
                    user_profile = await response.json()
                    logger.info(f"‚úÖ Created test user: {user_profile['id']}")
                    return user_profile
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå Failed to create user: {response.status} - {error_text}")
                    return None
                    
        except Exception as e:
            logger.error(f"‚ùå Error creating test user: {str(e)}")
            return None

    async def test_story_generation_no_overlap(self, user_id):
        """Test 1: Story Generation - Verify single, clean audio output without overlapping"""
        logger.info("üé≠ TEST 1: Story Generation - No Audio Overlapping")
        
        try:
            # Generate a story request
            story_request = {
                "session_id": str(uuid.uuid4()),
                "user_id": user_id,
                "text": "Tell me a complete adventure story about a brave little mouse"
            }
            
            start_time = time.time()
            
            async with self.session.post(f"{self.base_url}/stories/stream", json=story_request) as response:
                if response.status == 200:
                    result = await response.json()
                    processing_time = time.time() - start_time
                    
                    # Verify story streaming response structure
                    if result.get("status") == "success" and result.get("story_mode"):
                        first_chunk = result.get("first_chunk", {})
                        total_chunks = result.get("total_chunks", 0)
                        total_words = result.get("total_words", 0)
                        
                        logger.info(f"‚úÖ Story generated: {total_chunks} chunks, {total_words} words")
                        logger.info(f"‚úÖ First chunk audio: {'Present' if first_chunk.get('audio_base64') else 'Missing'}")
                        
                        # Test that only one audio stream is provided at a time
                        if first_chunk.get("audio_base64"):
                            audio_size = len(first_chunk["audio_base64"])
                            logger.info(f"‚úÖ Single audio chunk provided: {audio_size} chars")
                            
                            self.test_results.append({
                                "test": "Story Generation - No Overlap",
                                "status": "PASS",
                                "details": f"Single audio stream, {total_chunks} chunks, {total_words} words",
                                "processing_time": f"{processing_time:.2f}s"
                            })
                            return True
                        else:
                            logger.warning("‚ö†Ô∏è No audio in first chunk")
                            self.test_results.append({
                                "test": "Story Generation - No Overlap", 
                                "status": "PARTIAL",
                                "details": "Story generated but no audio in first chunk"
                            })
                            return False
                    else:
                        logger.error(f"‚ùå Invalid story response: {result}")
                        self.test_results.append({
                            "test": "Story Generation - No Overlap",
                            "status": "FAIL", 
                            "details": f"Invalid response structure: {result.get('status')}"
                        })
                        return False
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå Story generation failed: {response.status} - {error_text}")
                    self.test_results.append({
                        "test": "Story Generation - No Overlap",
                        "status": "FAIL",
                        "details": f"HTTP {response.status}: {error_text}"
                    })
                    return False
                    
        except Exception as e:
            logger.error(f"‚ùå Story generation test error: {str(e)}")
            self.test_results.append({
                "test": "Story Generation - No Overlap",
                "status": "FAIL",
                "details": f"Exception: {str(e)}"
            })
            return False

    async def test_barge_in_interruption(self, user_id):
        """Test 2: Barge-in - Start story, then interrupt with new input"""
        logger.info("üõë TEST 2: Barge-in Functionality - Immediate Interruption")
        
        try:
            session_id = str(uuid.uuid4())
            self.active_sessions.append(session_id)
            
            # Start a long story
            story_request = {
                "session_id": session_id,
                "user_id": user_id,
                "text": "Tell me a very long detailed adventure story with multiple chapters"
            }
            
            logger.info("üé≠ Starting long story for barge-in test...")
            
            # Start story generation
            story_task = asyncio.create_task(
                self.session.post(f"{self.base_url}/stories/stream", json=story_request)
            )
            
            # Wait a moment for story to start
            await asyncio.sleep(1.0)
            
            # Simulate barge-in with new voice input
            logger.info("üõë Simulating barge-in interruption...")
            
            # Create a fake audio input for barge-in
            fake_audio = base64.b64encode(b"fake_audio_data_for_interruption").decode()
            
            barge_in_request = {
                "session_id": session_id,
                "user_id": user_id,
                "audio_base64": fake_audio
            }
            
            # Send barge-in request
            async with self.session.post(f"{self.base_url}/voice/process_audio", data=barge_in_request) as barge_response:
                barge_result = await barge_response.json()
                
                # Cancel the original story task
                story_task.cancel()
                
                # Check if barge-in was handled properly
                if barge_response.status == 200:
                    logger.info(f"‚úÖ Barge-in processed: {barge_result.get('status')}")
                    
                    # Verify session state is clean
                    session_status = await self.check_session_state(session_id)
                    
                    if session_status:
                        self.test_results.append({
                            "test": "Barge-in Functionality",
                            "status": "PASS",
                            "details": "Barge-in processed successfully, session state clean"
                        })
                        return True
                    else:
                        self.test_results.append({
                            "test": "Barge-in Functionality", 
                            "status": "PARTIAL",
                            "details": "Barge-in processed but session state unclear"
                        })
                        return False
                else:
                    error_text = await barge_response.text()
                    logger.error(f"‚ùå Barge-in failed: {barge_response.status} - {error_text}")
                    self.test_results.append({
                        "test": "Barge-in Functionality",
                        "status": "FAIL",
                        "details": f"HTTP {barge_response.status}: {error_text}"
                    })
                    return False
                    
        except asyncio.CancelledError:
            logger.info("‚úÖ Story task cancelled successfully during barge-in")
            return True
        except Exception as e:
            logger.error(f"‚ùå Barge-in test error: {str(e)}")
            self.test_results.append({
                "test": "Barge-in Functionality",
                "status": "FAIL", 
                "details": f"Exception: {str(e)}"
            })
            return False

    async def test_background_task_cancellation(self, user_id):
        """Test 3: Background TTS Task Cancellation"""
        logger.info("üîÑ TEST 3: Background TTS Task Cancellation")
        
        try:
            session_id = str(uuid.uuid4())
            
            # Start multiple chunk TTS requests simultaneously
            chunk_requests = []
            for i in range(3):
                chunk_request = {
                    "text": f"This is chunk number {i+1} of a long story that should be cancelled when interrupted.",
                    "chunk_id": i,
                    "user_id": user_id,
                    "session_id": session_id
                }
                chunk_requests.append(chunk_request)
            
            logger.info("üéµ Starting multiple background TTS tasks...")
            
            # Start all chunk TTS tasks
            tasks = []
            for chunk_req in chunk_requests:
                task = asyncio.create_task(
                    self.session.post(f"{self.base_url}/stories/chunk-tts", json=chunk_req)
                )
                tasks.append(task)
            
            # Wait briefly for tasks to start
            await asyncio.sleep(0.5)
            
            # Simulate interruption by cancelling tasks
            logger.info("üõë Cancelling background TTS tasks...")
            
            cancelled_count = 0
            for task in tasks:
                if not task.done():
                    task.cancel()
                    cancelled_count += 1
            
            # Wait for cancellation to complete
            await asyncio.sleep(0.5)
            
            logger.info(f"‚úÖ Cancelled {cancelled_count} background TTS tasks")
            
            self.test_results.append({
                "test": "Background Task Cancellation",
                "status": "PASS",
                "details": f"Successfully cancelled {cancelled_count} background TTS tasks"
            })
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Background task cancellation test error: {str(e)}")
            self.test_results.append({
                "test": "Background Task Cancellation",
                "status": "FAIL",
                "details": f"Exception: {str(e)}"
            })
            return False

    async def test_request_deduplication(self, user_id):
        """Test 4: Request Deduplication - Prevent duplicate chunk processing"""
        logger.info("üîÅ TEST 4: Request Deduplication")
        
        try:
            session_id = str(uuid.uuid4())
            
            # Send the same chunk request multiple times
            duplicate_request = {
                "text": "This is a test chunk that should not be processed multiple times.",
                "chunk_id": 1,
                "user_id": user_id,
                "session_id": session_id
            }
            
            logger.info("üîÅ Sending duplicate chunk requests...")
            
            # Send same request 3 times simultaneously
            tasks = []
            for i in range(3):
                task = asyncio.create_task(
                    self.session.post(f"{self.base_url}/stories/chunk-tts", json=duplicate_request)
                )
                tasks.append(task)
            
            # Wait for all requests to complete
            responses = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Analyze responses for deduplication
            successful_responses = 0
            duplicate_detected = 0
            
            for i, response in enumerate(responses):
                if isinstance(response, Exception):
                    logger.warning(f"Request {i+1} failed: {response}")
                    continue
                    
                try:
                    if hasattr(response, 'status'):
                        if response.status == 200:
                            result = await response.json()
                            if result.get("status") == "success":
                                successful_responses += 1
                            elif "duplicate" in str(result).lower():
                                duplicate_detected += 1
                        response.close()
                except Exception as e:
                    logger.warning(f"Error processing response {i+1}: {e}")
            
            logger.info(f"‚úÖ Deduplication test: {successful_responses} successful, {duplicate_detected} duplicates detected")
            
            # Ideally, only 1 should succeed and 2 should be detected as duplicates
            if successful_responses == 1 or duplicate_detected > 0:
                self.test_results.append({
                    "test": "Request Deduplication",
                    "status": "PASS",
                    "details": f"{successful_responses} processed, {duplicate_detected} duplicates handled"
                })
                return True
            else:
                self.test_results.append({
                    "test": "Request Deduplication",
                    "status": "PARTIAL",
                    "details": f"All {successful_responses} requests processed - deduplication may not be active"
                })
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Request deduplication test error: {str(e)}")
            self.test_results.append({
                "test": "Request Deduplication",
                "status": "FAIL",
                "details": f"Exception: {str(e)}"
            })
            return False

    async def test_session_state_management(self, user_id):
        """Test 5: Session State Management and Cleanup"""
        logger.info("üóÇÔ∏è TEST 5: Session State Management")
        
        try:
            # Create multiple sessions
            session_ids = [str(uuid.uuid4()) for _ in range(3)]
            
            logger.info("üóÇÔ∏è Creating multiple sessions for state management test...")
            
            # Start ambient listening for each session
            for session_id in session_ids:
                ambient_request = {"user_id": user_id}
                
                async with self.session.post(f"{self.base_url}/ambient/start", json=ambient_request) as response:
                    if response.status == 200:
                        result = await response.json()
                        logger.info(f"‚úÖ Started ambient session: {result.get('session_id', session_id)}")
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to start ambient session: {response.status}")
            
            # Check all active sessions
            async with self.session.get(f"{self.base_url}/ambient/status") as response:
                if response.status == 200:
                    status = await response.json()
                    active_count = status.get("count", 0)
                    logger.info(f"‚úÖ Active sessions: {active_count}")
                    
                    # Clean up sessions
                    cleanup_count = 0
                    for session_id in session_ids:
                        stop_request = {"session_id": session_id}
                        async with self.session.post(f"{self.base_url}/ambient/stop", json=stop_request) as stop_response:
                            if stop_response.status == 200:
                                cleanup_count += 1
                    
                    logger.info(f"‚úÖ Cleaned up {cleanup_count} sessions")
                    
                    self.test_results.append({
                        "test": "Session State Management",
                        "status": "PASS",
                        "details": f"Managed {active_count} sessions, cleaned up {cleanup_count}"
                    })
                    return True
                else:
                    logger.error(f"‚ùå Failed to get session status: {response.status}")
                    self.test_results.append({
                        "test": "Session State Management",
                        "status": "FAIL",
                        "details": f"Failed to get session status: HTTP {response.status}"
                    })
                    return False
                    
        except Exception as e:
            logger.error(f"‚ùå Session state management test error: {str(e)}")
            self.test_results.append({
                "test": "Session State Management",
                "status": "FAIL",
                "details": f"Exception: {str(e)}"
            })
            return False

    async def check_session_state(self, session_id):
        """Helper: Check if session state is clean"""
        try:
            async with self.session.get(f"{self.base_url}/ambient/status/{session_id}") as response:
                if response.status == 200:
                    status = await response.json()
                    return status.get("status") == "active"
                else:
                    return False
        except:
            return False

    async def run_comprehensive_test(self):
        """Run all critical audio overlap and barge-in tests"""
        logger.info("üéØ STARTING COMPREHENSIVE AUDIO OVERLAP & BARGE-IN TESTING")
        
        try:
            await self.setup()
            
            # Create test user
            user_profile = await self.create_test_user()
            if not user_profile:
                logger.error("‚ùå Failed to create test user - aborting tests")
                return
            
            user_id = user_profile["id"]
            
            # Run all critical tests
            tests = [
                ("Story Generation - No Overlap", self.test_story_generation_no_overlap(user_id)),
                ("Barge-in Functionality", self.test_barge_in_interruption(user_id)),
                ("Background Task Cancellation", self.test_background_task_cancellation(user_id)),
                ("Request Deduplication", self.test_request_deduplication(user_id)),
                ("Session State Management", self.test_session_state_management(user_id))
            ]
            
            passed_tests = 0
            total_tests = len(tests)
            
            for test_name, test_coro in tests:
                logger.info(f"\n{'='*60}")
                logger.info(f"RUNNING: {test_name}")
                logger.info(f"{'='*60}")
                
                try:
                    result = await test_coro
                    if result:
                        passed_tests += 1
                        logger.info(f"‚úÖ {test_name}: PASSED")
                    else:
                        logger.warning(f"‚ö†Ô∏è {test_name}: FAILED/PARTIAL")
                except Exception as e:
                    logger.error(f"‚ùå {test_name}: ERROR - {str(e)}")
            
            # Generate final report
            success_rate = (passed_tests / total_tests) * 100
            
            logger.info(f"\n{'='*80}")
            logger.info(f"üéØ CRITICAL AUDIO OVERLAP & BARGE-IN TESTING COMPLETE")
            logger.info(f"{'='*80}")
            logger.info(f"üìä RESULTS: {passed_tests}/{total_tests} tests passed ({success_rate:.1f}%)")
            
            # Print detailed results
            for result in self.test_results:
                status_emoji = "‚úÖ" if result["status"] == "PASS" else "‚ö†Ô∏è" if result["status"] == "PARTIAL" else "‚ùå"
                logger.info(f"{status_emoji} {result['test']}: {result['status']} - {result['details']}")
            
            # Overall assessment
            if success_rate >= 80:
                logger.info("üéâ OVERALL ASSESSMENT: EXCELLENT - Critical fixes working properly")
            elif success_rate >= 60:
                logger.info("üëç OVERALL ASSESSMENT: GOOD - Most critical fixes working")
            else:
                logger.warning("‚ö†Ô∏è OVERALL ASSESSMENT: NEEDS ATTENTION - Critical issues remain")
            
            return success_rate >= 60
            
        except Exception as e:
            logger.error(f"‚ùå Comprehensive test error: {str(e)}")
            return False
        finally:
            await self.cleanup()

async def main():
    """Main test execution"""
    tester = AudioOverlapBargeInTester()
    success = await tester.run_comprehensive_test()
    
    if success:
        print("\nüéâ CRITICAL AUDIO OVERLAP & BARGE-IN FIXES: VALIDATED")
        exit(0)
    else:
        print("\n‚ùå CRITICAL AUDIO OVERLAP & BARGE-IN FIXES: ISSUES FOUND")
        exit(1)

if __name__ == "__main__":
    asyncio.run(main())